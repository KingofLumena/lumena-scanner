# Lumena Scanner

Custom AI code scanner powered by Lumena's Flame Protocol â€” Driftprint, Vaultwatch, Token Shield.

## ğŸ” What is Lumena Scanner?

Lumena Scanner is a Python-based security code scanner that automatically detects:
- **Secrets & API Keys** (AWS, GitHub, Stripe, etc.)
- **AI Drift Signatures** (prompt injections, AI instruction leaks)
- **Dangerous Function Calls** (eval, exec, unsafe operations)

It runs on every push and pull request via GitHub Actions, providing immediate feedback on security issues.

## ğŸš€ Quick Start

### Run Locally
```bash
python .lumena/scan.py
```

### Automatic Scanning
The scanner runs automatically on every push and pull request via GitHub Actions.

## ğŸ—ï¸ Architecture

Lumena Scanner uses a modular detector architecture that makes it easy to add new security checks:

### Core Components

1. **BaseDetector** - Abstract base class for all detectors
2. **LumenaScanner** - Main orchestrator
3. **Finding** - Represents a security issue

### Built-in Detectors

#### ğŸ” Vaultwatch (Secret Detection)
Detects leaked credentials:
- AWS Keys, GitHub Tokens, Stripe Keys
- Private Keys (RSA, EC, DSA)
- Database connection strings
- Generic API keys and tokens

#### ğŸ”¥ Flame Overlay (AI Drift Detection)
Identifies AI security risks:
- AI instruction leaks
- Prompt injection attempts
- Suspicious AI patterns

#### ğŸ”Š Echo Anomaly (Dangerous Functions)
Detects unsafe code:
- Python: `eval()`, `exec()`, `pickle`, `os.system()`
- JavaScript: `eval()`, `innerHTML`, `document.write()`
- SQL injection risks
- Disabled security features

## ğŸ“Š Output

The scanner provides clear, actionable output:

```
ğŸ” Lumena Scanner starting...
ğŸ“Š Scanned 42 files

âš ï¸  Found 3 potential security issues:

ğŸ”´ HIGH Severity (2 issues):
--------------------------------------------------------------------------------
âš ï¸  [HIGH] Vaultwatch - config.py:15
   Potential AWS Access Key detected

âš ï¸  [HIGH] Echo Anomaly - utils.py:23
   Dangerous function detected: Python eval()

ğŸ”´ MEDIUM Severity (1 issues):
--------------------------------------------------------------------------------
âš ï¸  [MEDIUM] Flame Overlay - prompt.py:8
   Potential AI Instruction Leak detected

ğŸ“Œ Summary: 2 high, 1 medium, 0 low
```

## ğŸ”§ Extending the Scanner

Adding a new detector is simple:

```python
class MyDetector(BaseDetector):
    def __init__(self):
        super().__init__("My Detector")
    
    def scan_file(self, file_path: str, content: str) -> List[Finding]:
        findings = []
        # Add your detection logic here
        return findings
```

Then add it to the scanner in `.lumena/scan.py`:

```python
self.detectors = [
    VaultwatchDetector(),
    FlameOverlayDetector(),
    EchoAnomalyDetector(),
    MyDetector(),  # Add your detector
]
```

For a complete guide on creating custom detectors, see [EXTENDING.md](EXTENDING.md).

## ğŸ“‹ Exit Codes

- `0` - Success (no HIGH severity issues)
- `1` - Failure (HIGH severity issues found)

## ğŸ› ï¸ Configuration

The scanner automatically skips:
- Binary files (images, executables)
- Common dependency directories (`node_modules`, `venv`, etc.)
- Git directories (`.git`, `.github`)
- Large files (> 1MB)

## ğŸ“š Learn More

For detailed documentation on each detector, see [`.lumena/README.md`](.lumena/README.md).

## ğŸ¤ Contributing

Contributions are welcome! Feel free to add new detectors or improve existing ones.

## ğŸ“œ License

See [LICENSE](LICENSE) for details.
